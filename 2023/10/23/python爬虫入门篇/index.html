<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/themes/blue/pace-theme-minimal.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"xiaguyangdie.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="python爬虫入门篇">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬虫入门篇">
<meta property="og:url" content="https://xiaguyangdie.github.io/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/index.html">
<meta property="og:site_name" content="峡谷杨爹的个人博客">
<meta property="og:description" content="python爬虫入门篇">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://xiaguyangdie.github.io/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/image-20231023220151828.png">
<meta property="og:image" content="https://xiaguyangdie.github.io/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/image-20231023225853019.png">
<meta property="og:image" content="https://xiaguyangdie.github.io/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/image-20231023230313462.png">
<meta property="og:image" content="https://xiaguyangdie.github.io/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/image-20231025004027424.png">
<meta property="og:image" content="https://xiaguyangdie.github.io/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/image-20231026002548946.png">
<meta property="article:published_time" content="2023-10-22T17:40:21.709Z">
<meta property="article:modified_time" content="2024-03-23T15:19:03.540Z">
<meta property="article:author" content="峡谷杨爹">
<meta property="article:tag" content="测试">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://xiaguyangdie.github.io/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/image-20231023220151828.png">

<link rel="canonical" href="https://xiaguyangdie.github.io/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>python爬虫入门篇 | 峡谷杨爹的个人博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">峡谷杨爹的个人博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">学习使我快乐，游戏使我疯狂</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    

  <a href="https://github.com/xiaguyangdie" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xiaguyangdie.github.io/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/%E5%8D%9A%E5%AE%A2.webp">
      <meta itemprop="name" content="峡谷杨爹">
      <meta itemprop="description" content="write less, do more">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="峡谷杨爹的个人博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          python爬虫入门篇
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-10-23 01:40:21" itemprop="dateCreated datePublished" datetime="2023-10-23T01:40:21+08:00">2023-10-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-23 23:19:03" itemprop="dateModified" datetime="2024-03-23T23:19:03+08:00">2024-03-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
                </span>
            </span>

          
            <span id="/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/" class="post-meta-item leancloud_visitors" data-flag-title="python爬虫入门篇" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">评论次数：</span>
    
    <a title="valine" href="/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>42k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>39 分钟</span>
            </span>
            <div class="post-description">python爬虫入门篇</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lxml</span><br><span class="line">jsonpath</span><br><span class="line">bs4</span><br><span class="line">selenium == <span class="number">4.4</span></span><br><span class="line">requests</span><br><span class="line">scrapy</span><br></pre></td></tr></table></figure>

<h1 id="1-urllib"><a href="#1-urllib" class="headerlink" title="1.urllib"></a>1.urllib</h1><ul>
<li><p>urllib是Python内置的HTTP请求库，它包含5个模块：</p>
<ul>
<li>request：最基本的HTTP请求模块，可以用来模拟发送请求</li>
<li>error：异常处理模块，如果出现请求错误，可以捕获异常，然后进行重试或其他操作</li>
<li>parse：工具模块，提供了许多URL处理方法，如拆分、解析、合并等</li>
<li>robotparser：主要用于识别网站的rebots.txt文件，然后判断哪些网站可以爬，哪些网站不可以爬</li>
<li>response：一共有4个类：<ul>
<li>addbase类：继承自<code>tempfile._TemporaddaryFileWrapper</code>的一个子类，<code>_TemporaddaryFileWrapper</code>这个类及其父类主要额外做了关闭文件的工作</li>
<li>addclosehook：关闭文件的时候执行自定义的函数</li>
<li>addinfo：增加header信息</li>
<li>addinfourl：增加url和code信息</li>
</ul>
</li>
</ul>
<p><img src="image-20231023220151828.png" alt="python爬虫入门篇/image-20231023220151828"></p>
</li>
</ul>
<h2 id="1-1-urllib-request"><a href="#1-1-urllib-request" class="headerlink" title="1.1 urllib.request"></a>1.1 urllib.request</h2><ul>
<li><p>urllib.request 定义了一些打开 URL 的函数和类，包含授权验证、重定向、浏览器 cookies等</p>
</li>
<li><p>urllib.request 可以模拟浏览器的一个请求发起过程</p>
</li>
<li><p>常用方法：</p>
<ul>
<li>urllib.request.urlopen()</li>
<li>urllib.request.urlretrieve()</li>
<li>urllib.request.ProxyHandler()</li>
<li>urllib.request.build_opener()</li>
</ul>
</li>
<li><p>常用类：</p>
<ul>
<li>urllib.request.Request()</li>
</ul>
</li>
</ul>
<h3 id="1-1-1-urllib-request-urlopen"><a href="#1-1-1-urllib-request-urlopen" class="headerlink" title="1.1.1 urllib.request.urlopen()"></a>1.1.1 urllib.request.urlopen()</h3><ul>
<li><p>向网站发起请求并获取响应对象，返回一个 HTTPResponse 类型的对象</p>
</li>
<li><p>参数：</p>
<p><img src="image-20231023225853019.png" alt="python爬虫入门篇/image-20231023225853019"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">urlopen</span>(<span class="params">url, data=<span class="literal">None</span>, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,</span></span><br><span class="line"><span class="params">            *, cafile=<span class="literal">None</span>, capath=<span class="literal">None</span>, cadefault=<span class="literal">False</span>, context=<span class="literal">None</span></span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>url</strong>：url 地址，str或者Request对象</li>
<li><strong>data</strong>：发送到服务器的其他数据对象，默认为 None</li>
<li><strong>timeout</strong>：设置访问超时时间，单位：秒</li>
<li><strong>cafile 和 capath</strong>：cafile 为 CA 证书， capath 为 CA 证书的路径，使用 HTTPS 需要用到</li>
<li><strong>cadefault</strong>：已经被弃用</li>
<li><strong>context</strong>：ssl.SSLContext类型，用来指定 SSL 设置</li>
</ul>
</li>
<li><p>返回值：<code>&lt;class &#39;http.client.HTTPResponse&#39;&gt;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">一个类型：HTTPResponse</span></span><br><span class="line"><span class="string">六个方法：read、readline、readlines、getcode、geturl、getheaders</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line"><span class="comment"># 2.模拟浏览器向服务器发送请求，response响应</span></span><br><span class="line">response = urllib.request.urlopen(url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个类型六个方法</span></span><br><span class="line"><span class="comment"># response：&lt;class &#x27;http.client.HTTPResponse&#x27;&gt;</span></span><br><span class="line"><span class="comment"># print(type(response))  # HTTPResponse类型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照一个字节一个字节的去读</span></span><br><span class="line"><span class="comment"># content = response.read()</span></span><br><span class="line"><span class="comment"># print(content)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取多个字节</span></span><br><span class="line"><span class="comment"># content = response.read(5)</span></span><br><span class="line"><span class="comment"># print(content)  # b&#x27;&lt;html&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取一行</span></span><br><span class="line"><span class="comment"># content = response.readline()</span></span><br><span class="line"><span class="comment"># print(content)  # b&#x27;&lt;html&gt;\r\n&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照一行一行的去读</span></span><br><span class="line"><span class="comment"># content = response.readlines()</span></span><br><span class="line"><span class="comment"># print(content)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回状态码</span></span><br><span class="line"><span class="comment"># print(response.getcode())</span></span><br><span class="line"><span class="comment"># print(response.code())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回url地址</span></span><br><span class="line"><span class="comment"># print(response.geturl())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回状态信息</span></span><br><span class="line"><span class="comment"># print(response.getheaders())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回状态信息</span></span><br><span class="line"><span class="comment"># print(response.info())</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-1-2-urllib-request-urlretrieve"><a href="#1-1-2-urllib-request-urlretrieve" class="headerlink" title="1.1.2 urllib.request.urlretrieve()"></a>1.1.2 urllib.request.urlretrieve()</h3><ul>
<li><p>直接将远程数据下载到本地</p>
</li>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">urlretrieve</span>(<span class="params">url, filename=<span class="literal">None</span>, reporthook=<span class="literal">None</span>, data=<span class="literal">None</span></span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>url：外部或者本地url</li>
<li>filename：指定了保存到本地的路径（如果未指定该参数，urllib会生成一个临时文件来保存数据）</li>
<li>reporthook：是一个回调函数，当连接上服务器、以及相应的数据块传输完毕的时候会触发该回调。可以利用这个回调函数来显示当前的下载进度</li>
<li>data：指post到服务器的数据</li>
</ul>
</li>
<li><p>返回值：</p>
<ul>
<li>该方法返回一个包含两个元素的元组(filename, headers)，filename表示保存到本地的路径，header表示服务器的响应头</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载网页</span></span><br><span class="line">url_page = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># url：下载的路径   filename：文件名称</span></span><br><span class="line">res = urllib.request.urlretrieve(url_page, <span class="string">&#x27;baidu.html&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(res))  <span class="comment"># &lt;class &#x27;tuple&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(res)  <span class="comment"># (&#x27;baidu.html&#x27;, &lt;http.client.HTTPMessage object at 0x0000020BCF3801C8&gt;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载图片</span></span><br><span class="line"><span class="comment"># url_img = &#x27;https://game.gtimg.cn/images/yxzj/img201606/heroimg/112/112-smallskin-5.jpg&#x27;</span></span><br><span class="line"><span class="comment"># urllib.request.urlretrieve(url=url_img, filename=&#x27;鲁班七号-星空梦想.jpg&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载视频</span></span><br><span class="line"><span class="comment"># url_video = &#x27;https://vd4.bdstatic.com/mda-pjdfyhzr62ggz4hn/sc/h264/1697282149339714793/mda-pjdfyhzr62ggz4hn.mp4?v_from_s=hkapp-haokan-suzhou&amp;auth_key=1697312028-0-0-08083c78d0d8872c8c6334ea30b8167c&amp;bcevod_channel=searchbox_feed&amp;pd=1&amp;cr=2&amp;cd=0&amp;pt=3&amp;logid=2028505532&amp;vid=6713350930922365115&amp;klogid=2028505532&amp;abtest=112345_1-112751_3-112954_2-113704_2&#x27;</span></span><br><span class="line"><span class="comment"># urllib.request.urlretrieve(url=url_video, filename=&#x27;鲁班七号.mp4&#x27;)</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-1-3-urllib-request-Request"><a href="#1-1-3-urllib-request-Request" class="headerlink" title="1.1.3 urllib.request.Request()"></a>1.1.3 urllib.request.Request()</h3><ul>
<li><p>主要用于构造一个 url，返回一个 urllib.request.Request 对象</p>
</li>
<li><p>参数：</p>
<p><img src="image-20231023230313462.png" alt="python爬虫入门篇/image-20231023230313462"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">             url: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">             data: <span class="built_in">bytes</span> | SupportsRead[<span class="built_in">bytes</span>] | Iterable[<span class="built_in">bytes</span>] | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">             headers: MutableMapping[<span class="built_in">str</span>, <span class="built_in">str</span>] = ...,</span></span><br><span class="line"><span class="params">             origin_req_host: <span class="built_in">str</span> | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">             unverifiable: <span class="built_in">bool</span> = ...,</span></span><br><span class="line"><span class="params">             method: <span class="built_in">str</span> | <span class="literal">None</span> = ...</span>) -&gt; <span class="literal">None</span></span><br></pre></td></tr></table></figure>

<ul>
<li>url：url 地址</li>
<li>data：发送到服务器的其他数据对象，默认为 None，必须传bytes类型，如果是字典，先使用urllib.parse里的urlencode()</li>
<li>headers：是一个字典，请求头，直接构造或者用add_header()方法添加（HTTP 请求的头部信息，字典格式）</li>
<li>origin_rep_host：请求方的名称或者ip地址</li>
<li>unverifiable：默认为false，表示这个请求是否无法验证。如果没有抓取的权限，此时值就是true</li>
<li>method：用来指示请求使用的方法</li>
</ul>
</li>
<li><p>返回值：urllib.request.Request 对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># request = urllib.request.Request(url, [], headers)</span></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(request))  <span class="comment"># &lt;class &#x27;urllib.request.Request&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"><span class="built_in">print</span>(response.read().decode(<span class="string">&quot;utf-8&quot;</span>))</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-1-4-urllib-request-ProxyHandler"><a href="#1-1-4-urllib-request-ProxyHandler" class="headerlink" title="1.1.4 urllib.request.ProxyHandler()"></a>1.1.4 urllib.request.ProxyHandler()</h3><h3 id="1-1-5-urllib-request-build-opener"><a href="#1-1-5-urllib-request-build-opener" class="headerlink" title="1.1.5 urllib.request.build_opener()"></a>1.1.5 urllib.request.build_opener()</h3><h2 id="1-2-urllib-parse"><a href="#1-2-urllib-parse" class="headerlink" title="1.2 urllib.parse"></a>1.2 urllib.parse</h2><ul>
<li>用于解析和组建 URL</li>
<li>常用方法：<ul>
<li>urllib.parse.urlparse()</li>
<li>urllib.parse.quote()</li>
<li>urllib.parse.urlencode()</li>
<li>urllib.parse.unquote()</li>
</ul>
</li>
</ul>
<h3 id="1-2-1-urllib-parse-urlparse"><a href="#1-2-1-urllib-parse-urlparse" class="headerlink" title="1.2.1 urllib.parse.urlparse()"></a>1.2.1 urllib.parse.urlparse()</h3><ul>
<li><p>用于解析 URL</p>
</li>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">urlparse</span>(<span class="params">url: <span class="built_in">bytes</span> | <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             scheme: <span class="built_in">bytes</span> | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">             allow_fragments: <span class="built_in">bool</span> = ...</span>) -&gt; ParseResultBytes</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">urlparse</span>(<span class="params">url, scheme=<span class="string">&#x27;&#x27;</span>, allow_fragments=<span class="literal">True</span></span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>url： url 地址</li>
<li>scheme：为协议类型</li>
<li>allow_fragments：参数为 false，则无法识别片段标识符。相反，它们被解析为路径，参数或查询组件的一部分，并 fragment 在返回值中设置为空字符串</li>
</ul>
</li>
<li><p>返回值：</p>
<ul>
<li>返回一个 URL 对象，这个对象包含 URL 的各个组成部分(ParseResult)</li>
<li>内容是一个元组，包含 6 个字符串：协议，位置，路径，参数，查询，判断</li>
</ul>
<table>
<thead>
<tr>
<th align="left">属性</th>
<th align="left">索引</th>
<th align="left">值</th>
<th align="left">值（如果不存在）</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>scheme</code></td>
<td align="left">0</td>
<td align="left">URL协议</td>
<td align="left">scheme 参数</td>
</tr>
<tr>
<td align="left"><code>netloc</code></td>
<td align="left">1</td>
<td align="left">网络位置部分</td>
<td align="left">空字符串</td>
</tr>
<tr>
<td align="left"><code>path</code></td>
<td align="left">2</td>
<td align="left">分层路径</td>
<td align="left">空字符串</td>
</tr>
<tr>
<td align="left"><code>params</code></td>
<td align="left">3</td>
<td align="left">最后路径元素的参数</td>
<td align="left">空字符串</td>
</tr>
<tr>
<td align="left"><code>query</code></td>
<td align="left">4</td>
<td align="left">查询组件</td>
<td align="left">空字符串</td>
</tr>
<tr>
<td align="left"><code>fragment</code></td>
<td align="left">5</td>
<td align="left">片段识别</td>
<td align="left">空字符串</td>
</tr>
<tr>
<td align="left"><code>username</code></td>
<td align="left"></td>
<td align="left">用户名</td>
<td align="left"><code>None</code></td>
</tr>
<tr>
<td align="left"><code>password</code></td>
<td align="left"></td>
<td align="left">密码</td>
<td align="left"><code>None</code></td>
</tr>
<tr>
<td align="left"><code>hostname</code></td>
<td align="left"></td>
<td align="left">主机名（小写）</td>
<td align="left"><code>None</code></td>
</tr>
<tr>
<td align="left"><code>port</code></td>
<td align="left"></td>
<td align="left">端口号为整数（如果存在）</td>
<td align="left"><code>None</code></td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line"></span><br><span class="line">url = urlparse(<span class="string">&#x27;https://www.xiaguyangdie.com/path?name=yang&amp;age=25#login&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(url))  <span class="comment"># &lt;class &#x27;urllib.parse.ParseResult&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(url)  <span class="comment"># ParseResult(scheme=&#x27;https&#x27;, netloc=&#x27;www.xiaguyangdie.com&#x27;, path=&#x27;/path&#x27;, params=&#x27;&#x27;, query=&#x27;name=yang&amp;age=25&#x27;, fragment=&#x27;login&#x27;)</span></span><br><span class="line"><span class="built_in">print</span>(url.scheme)  <span class="comment"># 输出：&#x27;http&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(url.netloc)  <span class="comment"># 输出：&#x27;www.xiaguyangdie.com&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(url.path)    <span class="comment"># 输出：&#x27;/path&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(url.params)  <span class="comment"># 输出：&#x27;&#x27;，因为没有参数</span></span><br><span class="line"><span class="built_in">print</span>(url.query)   <span class="comment"># 输出：&#x27;name=yang&amp;age=25&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(url.fragment)  <span class="comment"># 输出：&#x27;login&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(url.geturl())  <span class="comment"># https://www.xiaguyangdie.com/path?name=yang&amp;age=25#login</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-2-2-urllib-parse-quote"><a href="#1-2-2-urllib-parse-quote" class="headerlink" title="1.2.2 urllib.parse.quote()"></a>1.2.2 urllib.parse.quote()</h3><ul>
<li><p>对url地址中的中文进行编码(url编码)</p>
</li>
<li><p><strong>只能对字符串编码</strong></p>
</li>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">quote</span>(<span class="params">string: <span class="built_in">bytes</span>,</span></span><br><span class="line"><span class="params">          safe: <span class="built_in">bytes</span> | <span class="built_in">str</span> = ...</span>) -&gt; <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">quote</span>(<span class="params">string, safe=<span class="string">&#x27;/&#x27;</span>, encoding=<span class="literal">None</span>, errors=<span class="literal">None</span></span>)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>string</td>
<td>查询参数</td>
</tr>
<tr>
<td>safe</td>
<td>安全默认值</td>
</tr>
<tr>
<td>encoding</td>
<td>编码</td>
</tr>
<tr>
<td>errors</td>
<td>错误默认值</td>
</tr>
</tbody></table>
</li>
<li><p>返回值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">searchWord = urllib.parse.quote(<span class="string">&quot;蝙蝠侠&quot;</span>)   <span class="comment"># 中文  =&gt; Unicode编码</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(searchWord))  <span class="comment"># &lt;class &#x27;str&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(searchWord)  <span class="comment"># %E8%9D%99%E8%9D%A0%E4%BE%A0</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-2-3-urllib-parse-urlencode"><a href="#1-2-3-urllib-parse-urlencode" class="headerlink" title="1.2.3 urllib.parse.urlencode()"></a>1.2.3 urllib.parse.urlencode()</h3><ul>
<li><p>对url地址中的中文进行编码(url编码)</p>
</li>
<li><p>对字典或由两元素元组组成的列表进行码编码</p>
</li>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">urlencode</span>(<span class="params">query: Mapping | Mapping[<span class="type">Any</span>, <span class="type">Sequence</span>] | <span class="type">Sequence</span>[<span class="type">Tuple</span>[<span class="type">Any</span>, <span class="type">Any</span>]] | <span class="type">Sequence</span>[<span class="type">Tuple</span>[<span class="type">Any</span>, <span class="type">Sequence</span>]],</span></span><br><span class="line"><span class="params">              doseq: <span class="built_in">bool</span> = ...,</span></span><br><span class="line"><span class="params">              safe: <span class="built_in">bytes</span> | <span class="built_in">str</span> = ...,</span></span><br><span class="line"><span class="params">              encoding: <span class="built_in">str</span> = ...,</span></span><br><span class="line"><span class="params">              errors: <span class="built_in">str</span> = ...,</span></span><br><span class="line"><span class="params">              quote_via: (<span class="params">AnyStr, <span class="built_in">bytes</span> | <span class="built_in">str</span>, <span class="built_in">str</span>, <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span> = ...</span>)</span><br><span class="line">  -&gt; <span class="built_in">str</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">urlencode</span>(<span class="params">query, doseq=<span class="literal">False</span>, safe=<span class="string">&#x27;&#x27;</span>, encoding=<span class="literal">None</span>, errors=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">              quote_via=quote_plus</span>)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>query</td>
<td>查询参数</td>
</tr>
<tr>
<td>doseq</td>
<td>序列元素是否单独转换</td>
</tr>
<tr>
<td>safe</td>
<td>安全默认值</td>
</tr>
<tr>
<td>encoding</td>
<td>编码</td>
</tr>
<tr>
<td>errors</td>
<td>错误默认值</td>
</tr>
<tr>
<td>quote_via</td>
<td>查询参数的成份是str时，safe, encoding, errors传递给的指定函数 默认为<code>quote_plus()</code>，加强版quote()</td>
</tr>
</tbody></table>
</li>
<li><p>返回值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;k1&#x27;</span>: <span class="string">&#x27;鲁班七号&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;k2&#x27;</span>: <span class="string">&#x27;value2&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">searchWord = urllib.parse.urlencode(data)   <span class="comment"># 中文  =&gt; Unicode编码</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(searchWord))  <span class="comment"># &lt;class &#x27;str&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(searchWord)  <span class="comment"># k1=%E9%B2%81%E7%8F%AD%E4%B8%83%E5%8F%B7&amp;k2=value2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">searchWord = urllib.parse.urlencode(((<span class="string">&quot;k1&quot;</span>, <span class="string">&quot;鲁班七号&quot;</span>), (<span class="string">&#x27;k2&#x27;</span>, <span class="string">&quot;b1&quot;</span>)))</span><br><span class="line"><span class="built_in">print</span>(searchWord)  <span class="comment"># k1=%E9%B2%81%E7%8F%AD%E4%B8%83%E5%8F%B7&amp;k2=b1</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-2-4-urllib-parse-unquote"><a href="#1-2-4-urllib-parse-unquote" class="headerlink" title="1.2.4 urllib.parse.unquote()"></a>1.2.4 urllib.parse.unquote()</h3><ul>
<li><p>对url地址进行解码，作用是将编码后的字符串转为普通的unicode字符串</p>
</li>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">unquote</span>(<span class="params">string: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">            encoding: <span class="built_in">str</span> = ...,</span></span><br><span class="line"><span class="params">            errors: <span class="built_in">str</span> = ...</span>) -&gt; <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">unquote</span>(<span class="params">string, encoding=<span class="string">&#x27;utf-8&#x27;</span>, errors=<span class="string">&#x27;replace&#x27;</span></span>)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>string</td>
<td>查询参数</td>
</tr>
<tr>
<td>encoding</td>
<td>编码</td>
</tr>
<tr>
<td>errors</td>
<td>错误默认值</td>
</tr>
</tbody></table>
</li>
<li><p>返回值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">searchWord = urllib.parse.quote(<span class="string">&quot;鲁班七号&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(searchWord)  <span class="comment"># %E9%B2%81%E7%8F%AD%E4%B8%83%E5%8F%B7</span></span><br><span class="line"></span><br><span class="line">un_searchWord = urllib.parse.unquote(searchWord)</span><br><span class="line"><span class="built_in">print</span>(un_searchWord)  <span class="comment"># 鲁班七号</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="1-3-urllib-error"><a href="#1-3-urllib-error" class="headerlink" title="1.3 urllib.error"></a>1.3 urllib.error</h2><ul>
<li><p>urllib.error 模块为 urllib.request 所引发的异常定义了异常类，基础异常类是 URLError</p>
</li>
<li><p>常用类：</p>
<ul>
<li>ContentTooShortError</li>
<li>HTTPError</li>
<li>URLError</li>
</ul>
</li>
</ul>
<h3 id="1-3-1-urllib-error-ContentTooShortError"><a href="#1-3-1-urllib-error-ContentTooShortError" class="headerlink" title="1.3.1 urllib.error.ContentTooShortError"></a>1.3.1 urllib.error.ContentTooShortError</h3><ul>
<li><p>ContentTooShortError是 URLError 的一个子类</p>
</li>
<li><p>下载的大小与内容长度不匹配时引发异常</p>
</li>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ContentTooShortError</span>(<span class="title class_ inherited__">URLError</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Exception raised when downloaded size does not match content-length.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, message, content</span>):</span><br><span class="line">        URLError.__init__(self, message)</span><br><span class="line">        self.content = content</span><br></pre></td></tr></table></figure>
</li>
<li><p>返回值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">re_down</span>(<span class="params">url,filename</span>): </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        urllib.request.urlretrieve(url,filename)</span><br><span class="line">    <span class="keyword">except</span> urllib.error.ContentTooShortError:</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&#x27;Network conditions is not good. Reloading...&#x27;</span>)</span><br><span class="line">        re_down(url,filename)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-3-2-urllib-error-HTTPError"><a href="#1-3-2-urllib-error-HTTPError" class="headerlink" title="1.3.2 urllib.error.HTTPError"></a>1.3.2 urllib.error.HTTPError</h3><ul>
<li><p>HTTPError 是 URLError 的一个子类，用于处理特殊 HTTP 错误例如作为认证请求的时候，包含的属性 <strong>code</strong> 为 HTTP 的状态码， <strong>reason</strong> 为引发异常的原因，<strong>headers</strong> 为导致 HTTPError 的特定 HTTP 请求的 HTTP 响应头</p>
</li>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">HTTPError</span>(URLError, urllib.response.addinfourl):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Raised when HTTP error occurs, but also acts like non-error return&quot;&quot;&quot;</span></span><br><span class="line">    __super_init = urllib.response.addinfourl.__init__</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, url, code, msg, hdrs, fp</span>):</span><br><span class="line">        self.code = code</span><br><span class="line">        self.msg = msg</span><br><span class="line">        self.hdrs = hdrs</span><br><span class="line">        self.fp = fp</span><br><span class="line">        self.filename = url</span><br><span class="line">        <span class="comment"># The addinfourl classes depend on fp being a valid file</span></span><br><span class="line">        <span class="comment"># object.  In some cases, the HTTPError may not have a valid</span></span><br><span class="line">        <span class="comment"># file object.  If this happens, the simplest workaround is to</span></span><br><span class="line">        <span class="comment"># not initialize the base classes.</span></span><br><span class="line">        <span class="keyword">if</span> fp <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.__super_init(fp, hdrs, url, code)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;HTTP Error %s: %s&#x27;</span> % (self.code, self.msg)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&lt;HTTPError %s: %r&gt;&#x27;</span> % (self.code, self.msg)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># since URLError specifies a .reason attribute, HTTPError should also</span></span><br><span class="line">    <span class="comment">#  provide this attribute. See issue13211 for discussion.</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reason</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.msg</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">headers</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.hdrs</span><br><span class="line"></span><br><span class="line"><span class="meta">    @headers.setter</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">headers</span>(<span class="params">self, headers</span>):</span><br><span class="line">        self.hdrs = headers</span><br></pre></td></tr></table></figure>
</li>
<li><p>返回值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"></span><br><span class="line">myURL1 = urllib.request.urlopen(<span class="string">&quot;https://www.runoob.com/&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(myURL1.getcode())   <span class="comment"># 200</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    myURL2 = urllib.request.urlopen(<span class="string">&quot;https://www.runoob.com/no.html&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> urllib.error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">if</span> e.code == <span class="number">404</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">404</span>)   <span class="comment"># 404</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-3-3-urllib-error-URLError"><a href="#1-3-3-urllib-error-URLError" class="headerlink" title="1.3.3 urllib.error.URLError"></a>1.3.3 urllib.error.URLError</h3><ul>
<li><p>URLError 是 OSError 的一个子类，用于处理程序在遇到问题时会引发此异常（或其派生的异常），包含的属性 reason 为引发异常的原因</p>
</li>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">URLError</span>(<span class="title class_ inherited__">OSError</span>):</span><br><span class="line">    <span class="comment"># URLError is a sub-type of OSError, but it doesn&#x27;t share any of</span></span><br><span class="line">    <span class="comment"># the implementation.  need to override __init__ and __str__.</span></span><br><span class="line">    <span class="comment"># It sets self.args for compatibility with other OSError</span></span><br><span class="line">    <span class="comment"># subclasses, but args doesn&#x27;t have the typical format with errno in</span></span><br><span class="line">    <span class="comment"># slot 0 and strerror in slot 1.  This may be better than nothing.</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, reason, filename=<span class="literal">None</span></span>):</span><br><span class="line">        self.args = reason,</span><br><span class="line">        self.reason = reason</span><br><span class="line">        <span class="keyword">if</span> filename <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.filename = filename</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&lt;urlopen error %s&gt;&#x27;</span> % self.reason</span><br></pre></td></tr></table></figure>
</li>
<li><p>返回值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">urllib.error.URLError: &lt;urlopen error [Errno <span class="number">11001</span>] getaddrinfo failed&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    searchWord = urllib.parse.quote(<span class="string">&quot;蝙蝠侠&quot;</span>)</span><br><span class="line"></span><br><span class="line">    url = <span class="string">&#x27;https://www.sogou1.com/web?query=&#x27;</span> + searchWord</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    requestObj = urllib.request.Request(url=url, headers=headers)</span><br><span class="line">    response = urllib.request.urlopen(requestObj)</span><br><span class="line">    context = response.read().decode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(context)</span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)  <span class="comment"># &lt;urlopen error [Errno 11001] getaddrinfo failed&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="1-4-urllib-robotparser"><a href="#1-4-urllib-robotparser" class="headerlink" title="1.4 urllib.robotparser"></a>1.4 urllib.robotparser</h2><ul>
<li>urllib.robotparser 用于解析 robots.txt 文件</li>
<li>robots.txt（统一小写）是一种存放于网站根目录下的 robots 协议，它通常用于告诉搜索引擎对网站的抓取规则</li>
<li>常用类：<ul>
<li>RobotFileParser</li>
<li>RuleLine</li>
<li>Entry</li>
</ul>
</li>
</ul>
<h3 id="1-4-1-urllib-robotparser-RobotFileParser"><a href="#1-4-1-urllib-robotparser-RobotFileParser" class="headerlink" title="1.4.1 urllib.robotparser.RobotFileParser"></a>1.4.1 urllib.robotparser.RobotFileParser</h3><h3 id="1-4-2-urllib-robotparser-RuleLine"><a href="#1-4-2-urllib-robotparser-RuleLine" class="headerlink" title="1.4.2 urllib.robotparser.RuleLine"></a>1.4.2 urllib.robotparser.RuleLine</h3><h3 id="1-4-3-urllib-robotparser-Entry"><a href="#1-4-3-urllib-robotparser-Entry" class="headerlink" title="1.4.3 urllib.robotparser.Entry"></a>1.4.3 urllib.robotparser.Entry</h3><h2 id="1-5-urllib-response"><a href="#1-5-urllib-response" class="headerlink" title="1.5 urllib.response"></a>1.5 urllib.response</h2><ul>
<li>常用类：<ul>
<li>urllib.response.addbase()</li>
<li>urllib.response.addclosehook()</li>
<li>urllib.response.addinfo()</li>
<li>urllib.response.addinfourl()</li>
</ul>
</li>
</ul>
<h1 id="2-lxml"><a href="#2-lxml" class="headerlink" title="2.lxml"></a>2.lxml</h1><ul>
<li><p>基本使用：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span> /&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">title</span>&gt;</span>测试xpath<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">li</span> <span class="attr">id</span>=<span class="string">&quot;l1&quot;</span> <span class="attr">class</span>=<span class="string">&quot;c1&quot;</span>&gt;</span>武汉<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">li</span> <span class="attr">id</span>=<span class="string">&quot;l2&quot;</span> <span class="attr">class</span>=<span class="string">&quot;a2&quot;</span>&gt;</span>杭州<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">li</span> <span class="attr">id</span>=<span class="string">&quot;c3&quot;</span>&gt;</span>常州<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">li</span> <span class="attr">id</span>=<span class="string">&quot;c4&quot;</span>&gt;</span>宿迁<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">li</span>&gt;</span>北京<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">li</span>&gt;</span>成都<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">li</span>&gt;</span>泉州<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">li</span>&gt;</span>绍兴<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># xpath解析</span></span><br><span class="line"><span class="comment"># 1.本地文件  etree.parse()</span></span><br><span class="line"><span class="comment"># 2.服务器响应的数据   response.read().decode(&quot;utf-8&quot;)   etree.HTML()</span></span><br><span class="line"></span><br><span class="line">tree = etree.parse(<span class="string">&#x27;F:\\Python\\Project\\spider_start\\02-初识爬虫-解析\\1.xpath\\1.xpath的基本使用.html&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(tree)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ul下的li</span></span><br><span class="line"><span class="comment"># li_list = tree.xpath(&#x27;//body/ul/li&#x27;)</span></span><br><span class="line"><span class="comment"># li_list = tree.xpath(&#x27;//body//li&#x27;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找所有有id属性的li标签</span></span><br><span class="line"><span class="comment"># text()获取标签中的内容</span></span><br><span class="line"><span class="comment"># li_list = tree.xpath(&#x27;//ul/li[@id]&#x27;)</span></span><br><span class="line"><span class="comment"># li_list = tree.xpath(&#x27;//ul/li[@id]/text()&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到id为l1的li标签</span></span><br><span class="line"><span class="comment"># li_list = tree.xpath(&#x27;//ul/li[@id=&quot;l1&quot;]/text()&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到id为l2标签的class的属性值</span></span><br><span class="line"><span class="comment"># li_list = tree.xpath(&#x27;//ul/li[@id=&quot;l2&quot;]/@class&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询id中包含l的li标签</span></span><br><span class="line"><span class="comment"># li_list = tree.xpath(&#x27;//ul/li[contains(@id,&quot;l&quot;)]/text()&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询id的值以l开头的li标签</span></span><br><span class="line"><span class="comment"># li_list = tree.xpath(&#x27;//ul/li[starts-with(@id,&quot;l&quot;)]/text()&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询id为l1和class为c1的li标签</span></span><br><span class="line"><span class="comment"># li_list = tree.xpath(&#x27;//ul/li[@id=&quot;l1&quot; and @class=&quot;c1&quot;]/text()&#x27;)</span></span><br><span class="line"></span><br><span class="line">li_list = tree.xpath(<span class="string">&#x27;//ul/li[@id=&quot;l1&quot;]/text() | //ul/li[@id=&quot;l2&quot;]/text()&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断列表的长度</span></span><br><span class="line"><span class="built_in">print</span>(li_list)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(li_list))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.获取HTML</span></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.解析服务器响应的文件</span></span><br><span class="line">tree = etree.HTML(content)</span><br><span class="line"><span class="comment"># 获取想要的数据,xpath返回的数据是列表</span></span><br><span class="line">result = tree.xpath(<span class="string">&#x27;//input[@id=&quot;su&quot;]/@value&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载前10页图片</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># https://sc.chinaz.com/tupian/dongwutupian.html  1</span></span><br><span class="line"><span class="comment"># https://sc.chinaz.com/tupian/dongwutupian_page.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_request</span>(<span class="params">page</span>):</span><br><span class="line">    <span class="keyword">if</span> page == <span class="number">1</span>:</span><br><span class="line">        url = <span class="string">&#x27;https://sc.chinaz.com/tupian/dongwutupian.html&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        url = <span class="string">f&#x27;https://sc.chinaz.com/tupian/dongwutupian_<span class="subst">&#123;page&#125;</span>.html&#x27;</span></span><br><span class="line"></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line">    <span class="keyword">return</span> request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_content</span>(<span class="params">request</span>):</span><br><span class="line">    response = urllib.request.urlopen(request)</span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;UTF-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">down_load</span>(<span class="params">content</span>):</span><br><span class="line">    <span class="comment"># 下载图片</span></span><br><span class="line">    tree = etree.HTML(content)</span><br><span class="line">    url_list = tree.xpath(<span class="string">&#x27;//div[@class=&quot;tupian-list com-img-txt-list&quot;]//img/@data-original&#x27;</span>)</span><br><span class="line">    name_list = tree.xpath(<span class="string">&#x27;//div[@class=&quot;tupian-list com-img-txt-list&quot;]//img/@alt&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(name_list)):</span><br><span class="line">        name = name_list[i]</span><br><span class="line">        src = url_list[i]</span><br><span class="line">        url = <span class="string">&#x27;https:&#x27;</span> + src</span><br><span class="line">        urllib.request.urlretrieve(url=url, filename=<span class="string">&#x27;D:/站长素材图片下载/&#x27;</span> + name + <span class="string">&#x27;.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入起始页码：&#x27;</span>))</span><br><span class="line">    end_page = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入结束页码：&#x27;</span>))</span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(start_page, end_page + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 请求对象的定制</span></span><br><span class="line">        request = create_request(page)</span><br><span class="line">        <span class="comment"># 获取网页源码</span></span><br><span class="line">        content = get_content(request)</span><br><span class="line">        <span class="comment"># 下载图片</span></span><br><span class="line">        down_load(content)</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="3-jsonpath"><a href="#3-jsonpath" class="headerlink" title="3. jsonpath"></a>3. jsonpath</h1><ul>
<li><p>基本使用：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span> <span class="attr">&quot;store&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;book&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span> <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span> <span class="string">&quot;修真&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;六道&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;坏蛋是怎样练成的&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">8.95</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span> <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span> <span class="string">&quot;修真&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;天蚕土豆&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;斗破苍穹&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">12.99</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span> <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span> <span class="string">&quot;修真&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;唐家三少&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;斗罗大陆&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;isbn&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0-553-21311-3&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">8.99</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span> <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span> <span class="string">&quot;修真&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;我吃西红柿&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;星辰变&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;isbn&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0-395-19395-8&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">22.99</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;bicycle&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;老马&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;color&quot;</span><span class="punctuation">:</span> <span class="string">&quot;黑色&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">19.95</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> jsonpath</span><br><span class="line"></span><br><span class="line">obj = json.load(<span class="built_in">open</span>(<span class="string">&#x27;1.jsonpath的基本使用.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"><span class="comment"># print(obj)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 书的作者</span></span><br><span class="line"><span class="comment"># author_list = jsonpath.jsonpath(obj=obj, expr=&#x27;$.store.book[*].author&#x27;)</span></span><br><span class="line"><span class="comment"># print(author_list)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 所有作者</span></span><br><span class="line"><span class="comment"># author_list = jsonpath.jsonpath(obj=obj, expr=&#x27;$..author&#x27;)</span></span><br><span class="line"><span class="comment"># print(author_list)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># store下的所有的元素</span></span><br><span class="line"><span class="comment"># tag_list = jsonpath.jsonpath(obj=obj, expr=&#x27;$.store.*&#x27;)</span></span><br><span class="line"><span class="comment"># print(tag_list)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># store里面所有东西的price</span></span><br><span class="line"><span class="comment"># price_list = jsonpath.jsonpath(obj, &#x27;$.store..price&#x27;)</span></span><br><span class="line"><span class="comment"># print(price_list)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三本书</span></span><br><span class="line"><span class="comment"># book = jsonpath.jsonpath(obj, &#x27;$...book[2]&#x27;)</span></span><br><span class="line"><span class="comment"># print(book)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后一本书</span></span><br><span class="line"><span class="comment"># book = jsonpath.jsonpath(obj, &#x27;$..book[(@.length-1)]&#x27;)</span></span><br><span class="line"><span class="comment"># print(book)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 前两本书</span></span><br><span class="line"><span class="comment"># book_list = jsonpath.jsonpath(obj, &#x27;$..book[0,1]&#x27;)</span></span><br><span class="line"><span class="comment"># book_list = jsonpath.jsonpath(obj, &#x27;$..book[:2]&#x27;)</span></span><br><span class="line"><span class="comment"># print(book_list)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 过滤出所有包含版本号的书</span></span><br><span class="line"><span class="comment"># book_list = jsonpath.jsonpath(obj, &#x27;$..book[?(@.isbn)]&#x27;)</span></span><br><span class="line"><span class="comment"># print(book_list)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 那一本书超过了10元</span></span><br><span class="line">book_list = jsonpath.jsonpath(obj, <span class="string">&#x27;$..book[?(@.price&gt;10)]&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(book_list)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> jsonpath</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://dianying.taobao.com/cityAction.json?activityId&amp;_ksTS=1629789477003_137&amp;jsoncallback=jsonp138&amp;action=cityAction&amp;n_s=new&amp;event_submit_doGetAllRegion=true&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="comment"># 带冒号的请求头一般是不好使的</span></span><br><span class="line">    <span class="comment"># &#x27;:authority&#x27;: &#x27;dianying.taobao.com&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;:method&#x27;: &#x27;GET&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;:path&#x27;: &#x27;/cityAction.json?activityId&amp;_ksTS=1629789477003_137&amp;jsoncallback=jsonp138&amp;action=cityAction&amp;n_s=new&amp;event_submit_doGetAllRegion=true&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;:scheme&#x27;: &#x27;https&#x27;,</span></span><br><span class="line">    <span class="string">&#x27;accept&#x27;</span>: <span class="string">&#x27;text/javascript, application/javascript, application/ecmascript, application/x-ecmascript, */*; q=0.01&#x27;</span>,</span><br><span class="line">    <span class="comment"># 请求头中的编码限制要注释掉</span></span><br><span class="line">    <span class="comment"># &#x27;accept-encoding&#x27;: &#x27;gzip, deflate, br&#x27;,</span></span><br><span class="line">    <span class="string">&#x27;accept-language&#x27;</span>: <span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;cookie&#x27;</span>: <span class="string">&#x27;cna=UkO6F8VULRwCAXTqq7dbS5A8; miid=949542021157939863; sgcookie=E100F01JK9XMmyoZRigjfmZKExNdRHQqPf4v9NIWIC1nnpnxyNgROLshAf0gz7lGnkKvwCnu1umyfirMSAWtubqc4g%3D%3D; tracknick=action_li; _cc_=UIHiLt3xSw%3D%3D; enc=dA18hg7jG1xapfVGPHoQCAkPQ4as1%2FEUqsG4M6AcAjHFFUM54HWpBv4AAm0MbQgqO%2BiZ5qkUeLIxljrHkOW%2BtQ%3D%3D; hng=CN%7Czh-CN%7CCNY%7C156; thw=cn; _m_h5_tk=3ca69de1b9ad7dce614840fcd015dcdb_1629776735568; _m_h5_tk_enc=ab56df54999d1d2cac2f82753ae29f82; t=874e6ce33295bf6b95cfcfaff0af0db6; xlly_s=1; cookie2=13acd8f4dafac4f7bd2177d6710d60fe; v=0; _tb_token_=e65ebbe536158; tfstk=cGhRB7mNpnxkDmUx7YpDAMNM2gTGZbWLxUZN9U4ulewe025didli6j5AFPI8MEC..; l=eBrgmF1cOsMXqSxaBO5aFurza77tzIRb8sPzaNbMiInca6OdtFt_rNCK2Ns9SdtjgtfFBetPVKlOcRCEF3apbgiMW_N-1NKDSxJ6-; isg=BBoas2yXLzHdGp3pCh7XVmpja8A8S54lyLj1RySTHq14l7vRDNufNAjpZ2MLRxa9&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;referer&#x27;</span>: <span class="string">&#x27;https://dianying.taobao.com/&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-ch-ua&#x27;</span>: <span class="string">&#x27;&quot;Chromium&quot;;v=&quot;92&quot;, &quot; Not A;Brand&quot;;v=&quot;99&quot;, &quot;Google Chrome&quot;;v=&quot;92&quot;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-mobile&#x27;</span>: <span class="string">&#x27;?0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-dest&#x27;</span>: <span class="string">&#x27;empty&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-mode&#x27;</span>: <span class="string">&#x27;cors&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-site&#x27;</span>: <span class="string">&#x27;same-origin&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;x-requested-with&#x27;</span>: <span class="string">&#x27;XMLHttpRequest&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># split 切割，去掉获取的json文件中的开头结尾的圆括号及垃圾内容</span></span><br><span class="line"><span class="comment"># 以左括号为分割，取第二块数据，再以右括号为标准切割，取第一块数据</span></span><br><span class="line">content = content.split(<span class="string">&#x27;(&#x27;</span>)[<span class="number">1</span>].split(<span class="string">&#x27;)&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;爬虫_解析_jsonpath解析淘票票.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(content)</span><br><span class="line"></span><br><span class="line">obj = json.load(<span class="built_in">open</span>(<span class="string">&#x27;爬虫_解析_jsonpath解析淘票票.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"></span><br><span class="line">city_list = jsonpath.jsonpath(obj, <span class="string">&#x27;$..regionName&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(city_list)</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="4-bs4"><a href="#4-bs4" class="headerlink" title="4. bs4"></a>4. bs4</h1><ul>
<li><p>基本使用：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Title<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>张三<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">li</span> <span class="attr">id</span>=<span class="string">&quot;l1&quot;</span>&gt;</span>李四<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">li</span> <span class="attr">id</span>=<span class="string">&quot;l2&quot;</span>&gt;</span>王五<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;&quot;</span> <span class="attr">class</span>=<span class="string">&quot;a1&quot;</span>&gt;</span>百度<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">span</span>&gt;</span>对对对<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;&quot;</span> <span class="attr">id</span>=<span class="string">&quot;&quot;</span> <span class="attr">title</span>=<span class="string">&quot;a2&quot;</span>&gt;</span>SF<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;d1&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">span</span>&gt;</span></span><br><span class="line">            哈哈哈</span><br><span class="line">        <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span> <span class="attr">id</span>=<span class="string">&quot;p1&quot;</span> <span class="attr">class</span>=<span class="string">&quot;p1&quot;</span>&gt;</span>呵呵呵<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过解析本地文件，理解bs4基础语法</span></span><br><span class="line"><span class="comment"># 默认打开的文件的编码格式是gbk，所以打开文件的时候需要指定编码</span></span><br><span class="line">soup = BeautifulSoup(<span class="built_in">open</span>(<span class="string">&#x27;1.bs4的基本使用.html&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>), <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(soup)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据标签名查找节点</span></span><br><span class="line"><span class="comment"># 找到的是第一个符合条件的数据</span></span><br><span class="line"><span class="comment"># print(soup.a)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取标签的属性和属性值</span></span><br><span class="line"><span class="comment"># print(soup.a.attrs)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># bs4的一些函数</span></span><br><span class="line"><span class="comment"># 1.find</span></span><br><span class="line"><span class="comment"># 返回第一个符合条件的数据</span></span><br><span class="line"><span class="comment"># print(soup.find(&#x27;a&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据title的值来找对应的标签对象</span></span><br><span class="line"><span class="comment"># print(soup.find(&#x27;a&#x27;, title=&#x27;a2&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据class的值来找对应的标签对象，主要class需要加下划线</span></span><br><span class="line"><span class="comment"># print(soup.find(&#x27;a&#x27;, class_=&#x27;a1&#x27;))</span></span><br><span class="line"><span class="comment"># 2.find_all，返回的是一个列表，并且返回所有a标签</span></span><br><span class="line"><span class="comment"># print(soup.find_all(&#x27;a&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果想获取的是多个标签的数据，那么需要在find_all的参数中添加列表数据</span></span><br><span class="line"><span class="comment"># print(soup.find_all([&#x27;a&#x27;, &#x27;span&#x27;]))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># limit的作用是查找前几个数据</span></span><br><span class="line"><span class="comment"># print(soup.find_all(&#x27;li&#x27;, limit=2))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.select(推荐)</span></span><br><span class="line"><span class="comment"># select方法返回的是一个列表，并且会返回多个数据</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;a&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以通过.代表class，类选择器</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;.a1&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以通过#代表id，id选择器</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;#l1&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 属性选择器---通过属性寻找对应的标签</span></span><br><span class="line"><span class="comment"># 查找li标签中有id的标签</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;li[id]&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找li标签中有id为l2的标签</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;li[id=&quot;l2&quot;]&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 层级选择器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 后代选择器</span></span><br><span class="line"><span class="comment"># 找到的div下面的li</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;div li&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 子代选择器</span></span><br><span class="line"><span class="comment"># 某标签的第一级子标签</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;div &gt; ul &gt; li&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到a标签和li标签的所有的对象</span></span><br><span class="line"><span class="comment"># print(soup.select(&#x27;a,li&#x27;))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 节点信息</span></span><br><span class="line"><span class="comment"># 获取节点内容</span></span><br><span class="line"><span class="comment"># obj = soup.select(&#x27;#d1&#x27;)[0]</span></span><br><span class="line"><span class="comment"># 如果标签对象中  只有内容   那么string和get_text()都可以使用</span></span><br><span class="line"><span class="comment"># 如果标签对象中  除了内容还有标签  那么string就获取不到数据  而get_text()可以获取到数据</span></span><br><span class="line"><span class="comment"># print(obj.string)</span></span><br><span class="line"><span class="comment"># print(obj.get_text())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 节点属性</span></span><br><span class="line"><span class="comment"># obj = soup.select(&#x27;#p1&#x27;)[0]</span></span><br><span class="line"><span class="comment"># name是标签的名字</span></span><br><span class="line"><span class="comment"># print(obj.name)</span></span><br><span class="line"><span class="comment"># 将属性值作为一个字典返回</span></span><br><span class="line"><span class="comment"># print(obj.attrs)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取节点的属性</span></span><br><span class="line"><span class="comment"># obj = soup.select(&#x27;#p1&#x27;)[0]</span></span><br><span class="line"><span class="comment"># print(obj.attrs.get(&#x27;class&#x27;))</span></span><br><span class="line"><span class="comment"># print(obj.get(&#x27;class&#x27;))</span></span><br><span class="line"><span class="comment"># print(obj[&#x27;class&#x27;])</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://www.starbucks.com.cn/menu/&#x27;</span></span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(url)</span><br><span class="line"></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(content, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># xpath方法</span></span><br><span class="line"><span class="comment"># //ul[@class=&quot;grid padded-3 product&quot;]//strong/text()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># bs4</span></span><br><span class="line">name_list = soup.select(<span class="string">&#x27;ul[class=&quot;grid padded-3 product&quot;] strong&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> name_list:</span><br><span class="line">    <span class="built_in">print</span>(name.get_text())</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="5-selenium"><a href="#5-selenium" class="headerlink" title="5.selenium"></a>5.selenium</h1><ul>
<li><p>下载驱动</p>
<ul>
<li>1.下载浏览器驱动：<a target="_blank" rel="noopener" href="https://chromedriver.storage.googleapis.com/index.html%E6%88%96%E8%80%85https://registry.npmmirror.com/binary.html?path=chromedriver/">https://chromedriver.storage.googleapis.com/index.html或者https://registry.npmmirror.com/binary.html?path=chromedriver/</a></li>
<li>2.下载的驱动应为跟你浏览器版本一致(最新版驱动：<a target="_blank" rel="noopener" href="https://googlechromelabs.github.io/chrome-for-testing/#stable">https://googlechromelabs.github.io/chrome-for-testing/#stable</a>)</li>
<li>3.解压出exe文件</li>
</ul>
</li>
<li><p>基本使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.service <span class="keyword">import</span> Service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建浏览器操作对象</span></span><br><span class="line">path = <span class="string">&#x27;chromedriver.exe&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">service = Service(executable_path=path)</span><br><span class="line">browser = webdriver.Chrome(service=service)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问网站</span></span><br><span class="line">url = <span class="string">&#x27;https://www.jd.com&#x27;</span></span><br><span class="line">browser.get(url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># content = browser.page_source</span></span><br><span class="line"><span class="comment"># print(content)</span></span><br></pre></td></tr></table></figure>

<p><img src="image-20231025004027424.png" alt="python爬虫入门篇/image-20231025004027424"></p>
</li>
</ul>
<h1 id="6-requests-重点"><a href="#6-requests-重点" class="headerlink" title="6.requests(重点)"></a>6.requests(重点)</h1><ul>
<li><p>官方文档：<a target="_blank" rel="noopener" href="https://requests.readthedocs.io/en/latest/">https://requests.readthedocs.io/en/latest/</a></p>
</li>
<li><p><strong>Requests</strong>是一个优雅而简单的 <code>Python HTTP</code> 库，可以方便地向网站发送 <code>HTTP</code> 请求，并获取响应结果</p>
</li>
<li><p>每次调用 <code>requests</code> 请求之后，会返回一个 response <code>&lt;class &#39;requests.models.Response&#39;&gt;</code>对象，该对象包含了具体的响应信息，如状态码、响应头、响应内容等</p>
</li>
<li><p>基本使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入 Requests 模块</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取某个网页</span></span><br><span class="line">url = <span class="string">&quot;http://www.baidu.com&quot;</span></span><br><span class="line">response = requests.get(url=url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个类型和六个属性</span></span><br><span class="line"><span class="comment"># print(type(response))  # &lt;class &#x27;requests.models.Response&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置响应的编码格式</span></span><br><span class="line"><span class="comment"># response.encoding = &#x27;utf-8&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以字符串的形式返回网页的源码</span></span><br><span class="line"><span class="comment"># print(response.text)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回url地址</span></span><br><span class="line"><span class="comment"># print(response.url)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回二进制数据</span></span><br><span class="line"><span class="comment"># print(response.content)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回响应状态码</span></span><br><span class="line"><span class="comment"># print(response.status_code)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回响应头</span></span><br><span class="line"><span class="built_in">print</span>(response.headers)</span><br></pre></td></tr></table></figure>
</li>
<li><p>response 对象：</p>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left">属性或方法</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">apparent_encoding</td>
<td align="left">编码方式</td>
</tr>
<tr>
<td align="left">close()</td>
<td align="left">关闭与服务器的连接</td>
</tr>
<tr>
<td align="left">content</td>
<td align="left">返回响应的内容，以字节为单位</td>
</tr>
<tr>
<td align="left">cookies</td>
<td align="left">返回一个 CookieJar 对象，包含了从服务器发回的 cookie</td>
</tr>
<tr>
<td align="left">elapsed</td>
<td align="left">返回一个 timedelta 对象，包含了从发送请求到响应到达之间经过的时间量，可以用于测试响应速度。比如 r.elapsed.microseconds 表示响应到达需要多少微秒。</td>
</tr>
<tr>
<td align="left">encoding</td>
<td align="left">解码 r.text 的编码方式</td>
</tr>
<tr>
<td align="left">headers</td>
<td align="left">返回响应头，字典格式</td>
</tr>
<tr>
<td align="left">history</td>
<td align="left">返回包含请求历史的响应对象列表（url）</td>
</tr>
<tr>
<td align="left">is_permanent_redirect</td>
<td align="left">如果响应是永久重定向的 url，则返回 True，否则返回 False</td>
</tr>
<tr>
<td align="left">is_redirect</td>
<td align="left">如果响应被重定向，则返回 True，否则返回 False</td>
</tr>
<tr>
<td align="left">iter_content()</td>
<td align="left">迭代响应</td>
</tr>
<tr>
<td align="left">iter_lines()</td>
<td align="left">迭代响应的行</td>
</tr>
<tr>
<td align="left">json()</td>
<td align="left">返回结果的 JSON 对象 (结果需要以 JSON 格式编写的，否则会引发错误)</td>
</tr>
<tr>
<td align="left">links</td>
<td align="left">返回响应的解析头链接</td>
</tr>
<tr>
<td align="left">next</td>
<td align="left">返回重定向链中下一个请求的 PreparedRequest 对象</td>
</tr>
<tr>
<td align="left">ok</td>
<td align="left">检查 “status_code” 的值，如果小于400，则返回 True，如果不小于 400，则返回 False</td>
</tr>
<tr>
<td align="left">raise_for_status()</td>
<td align="left">如果发生错误，方法返回一个 HTTPError 对象</td>
</tr>
<tr>
<td align="left">reason</td>
<td align="left">响应状态的描述，比如 “Not Found” 或 “OK”</td>
</tr>
<tr>
<td align="left">request</td>
<td align="left">返回请求此响应的请求对象</td>
</tr>
<tr>
<td align="left">status_code</td>
<td align="left">返回 http 的状态码，比如 404 和 200（200 是 OK，404 是 Not Found）</td>
</tr>
<tr>
<td align="left">text</td>
<td align="left">返回响应的内容，unicode 类型数据</td>
</tr>
<tr>
<td align="left">url</td>
<td align="left">返回响应的 URL</td>
</tr>
</tbody></table>
<ul>
<li><p>requests 方法：</p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">delete(url, kwargs)</td>
<td align="left">发送 DELETE 请求到指定 url</td>
</tr>
<tr>
<td align="left">get(url, params, kwargs)</td>
<td align="left">发送 GET 请求到指定 url</td>
</tr>
<tr>
<td align="left">head(url, kwargs)</td>
<td align="left">发送 HEAD 请求到指定 url</td>
</tr>
<tr>
<td align="left">patch(url, data, kwargs)</td>
<td align="left">发送 PATCH 请求到指定 url</td>
</tr>
<tr>
<td align="left">post(url, data, json, kwargs)</td>
<td align="left">发送 POST 请求到指定 url</td>
</tr>
<tr>
<td align="left">put(url, data, kwargs)</td>
<td align="left">发送 PUT 请求到指定 url</td>
</tr>
<tr>
<td align="left">request(method, url, kwargs)</td>
<td align="left">向指定的 url 发送指定的请求方法</td>
</tr>
</tbody></table>
</li>
</ul>
<h2 id="6-1-requests-post"><a href="#6-1-requests-post" class="headerlink" title="6.1 requests.post()"></a>6.1 requests.post()</h2><ul>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">post</span>(<span class="params">url: <span class="built_in">str</span> | <span class="built_in">bytes</span>,</span></span><br><span class="line"><span class="params">         data: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         json: <span class="type">Any</span> | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">         *,</span></span><br><span class="line"><span class="params">         params: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         headers: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         cookies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         files: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         auth: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         timeout: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         allow_redirects: <span class="built_in">bool</span> = ...,</span></span><br><span class="line"><span class="params">         proxies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         hooks: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         stream: <span class="built_in">bool</span> | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">         verify: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         cert: <span class="type">Any</span> = ...</span>) -&gt; Response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">post</span>(<span class="params">url, data=<span class="literal">None</span>, json=<span class="literal">None</span>, **kwargs</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>url</strong>：请求 url</p>
</li>
<li><p><strong>data</strong> ：（可选）参数为要发送到指定 url 的字典、元组列表、字节或文件对象</p>
</li>
<li><p><strong>json</strong> ：（可选）参数为要发送到指定 url 的 JSON 对象</p>
</li>
<li><p><strong>kwargs</strong> ：为其他参数，比如 cookies、headers、verify</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">params: URL 中的额外参数</span><br><span class="line">data: 请求中需要的数据</span><br><span class="line">json: JSON 格式的数据</span><br><span class="line">headers: 请求头</span><br><span class="line">cookies: 请求Cookies</span><br><span class="line">files: 文件上传</span><br><span class="line">auth: HTTP 基础认证</span><br><span class="line">timeout: 超时时间</span><br><span class="line">allow_redirects: 是否允许重定向，</span><br><span class="line">proxies: 代理</span><br><span class="line">verify: 是否验证证书</span><br><span class="line">stream: 是否从响应中立即下载响应体</span><br><span class="line">cert: SSL 证书</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>返回值：<code>&lt;class &#39;requests.models.Response&#39;&gt;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com/s?&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Cookie&quot;</span>: <span class="string">&quot;BIDUPSID=64DE66ED48DC8BDBD224879D62A0CFBE; PSTM=1666787830; BDUSS=jFPVFhMNVItUXgyVUtJMFVaS1dpb0RWemM1SGxUR2tPRW5Id0hnfm8xTnNYYVZqSVFBQUFBJCQAAAAAAAAAAAEAAADwCb2ds6y8tszsyrm1xMDhy64AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGzQfWNs0H1jM; BDUSS_BFESS=jFPVFhMNVItUXgyVUtJMFVaS1dpb0RWemM1SGxUR2tPRW5Id0hnfm8xTnNYYVZqSVFBQUFBJCQAAAAAAAAAAAEAAADwCb2ds6y8tszsyrm1xMDhy64AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGzQfWNs0H1jM; BD_UPN=12314753; BAIDUID=98674BA4D976ACB95A691562FDD4A375:SL=0:NR=10:FG=1; MCITY=-179%3A; H_WISE_SIDS=114551_216839_213358_214791_110085_244713_261716_236312_256419_265881_266154_266362_267298_265615_256302_267072_268592_266186_259642_269236_269779_269832_269905_269049_267066_256739_270460_264423_270548_271036_271051_271023_271170_271176_271077_257179_269771_271228_267659_271320_266028_270102_271865_271673_269854_271812_271949_271943_256154_234295_234208_271188_270055_272284_263618_267596_272335_272365_272011_272460_272505_253022_269729_272679_272610_272764_272822_272842_260335_269296_269715_273066_273094_273164_273118_273135_273008_273267_273236_273301_272984_273327_272492_273399_273392_271157_273518_272642_272818_271147_273670_273703_264170_270186_273740_273923_274082_273960_273966_274139_269609_273917_273348_274238_273788_273043_273595_256223_272805_203517_274356_272319_274413_8000084_8000106_8000122_8000136_8000150_8000165_8000177_8000176_8000185_8000190_8000203; H_WISE_SIDS_BFESS=114551_216839_213358_214791_110085_244713_261716_236312_256419_265881_266154_266362_267298_265615_256302_267072_268592_266186_259642_269236_269779_269832_269905_269049_267066_256739_270460_264423_270548_271036_271051_271023_271170_271176_271077_257179_269771_271228_267659_271320_266028_270102_271865_271673_269854_271812_271949_271943_256154_234295_234208_271188_270055_272284_263618_267596_272335_272365_272011_272460_272505_253022_269729_272679_272610_272764_272822_272842_260335_269296_269715_273066_273094_273164_273118_273135_273008_273267_273236_273301_272984_273327_272492_273399_273392_271157_273518_272642_272818_271147_273670_273703_264170_270186_273740_273923_274082_273960_273966_274139_269609_273917_273348_274238_273788_273043_273595_256223_272805_203517_274356_272319_274413_8000084_8000106_8000122_8000136_8000150_8000165_8000177_8000176_8000185_8000190_8000203; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; newlogin=1; sug=3; sugstore=1; ORIGIN=0; bdime=0; BAIDUID_BFESS=98674BA4D976ACB95A691562FDD4A375:SL=0:NR=10:FG=1; BA_HECTOR=al8ga1810h200024a4002k8g1iitbb41o; ZFY=SbvDUpsZs4z2bqnoRO2uA:AWW7JQ1NpdRetRkIE0RYiY:C; COOKIE_SESSION=4954_0_8_9_25_4_0_0_8_4_18_0_5019_0_87_0_1697562902_0_1697562815%7C9%23228131_305_1686278488%7C9; BDRCVFR[feWj1Vr5u3D]=I67x6TjHwwYf0; BD_CK_SAM=1; PSINO=3; delPer=0; H_PS_PSSID=39319_39445_39399_39396_39419_39411_39434_39497_39479_39461_26350_22160_39423; H_PS_645EC=dc89KW1ltGjICkb6oTS32IYallgY9XXyXxJO5J%2BgWJYqSg3wVvIIBxebUa0Sr4f%2F8v6o; WWW_ST=1697634533969&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;kw&#x27;</span>: <span class="string">&#x27;鲁班七号&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.post(url=url, data=data, headers=headers)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;requests.models.Response&#x27;&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="6-2-requests-get"><a href="#6-2-requests-get" class="headerlink" title="6.2  requests.get()"></a>6.2  requests.get()</h2><ul>
<li><p>参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get</span>(<span class="params">url: <span class="built_in">str</span> | <span class="built_in">bytes</span>,</span></span><br><span class="line"><span class="params">        params: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        *,</span></span><br><span class="line"><span class="params">        data: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        headers: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        cookies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        files: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        auth: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        timeout: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        allow_redirects: <span class="built_in">bool</span> = ...,</span></span><br><span class="line"><span class="params">        proxies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        hooks: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        stream: <span class="built_in">bool</span> | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">        verify: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        cert: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        json: <span class="type">Any</span> | <span class="literal">None</span> = ...</span>) -&gt; Response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get</span>(<span class="params">url, params=<span class="literal">None</span>, **kwargs</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>url</strong>：请求 url</li>
<li><strong>data</strong> ：（可选）参数为要发送到指定 url 的字典、元组列表、字节或文件对象</li>
<li><strong>kwargs</strong> ：为其他参数，比如 cookies、headers、verify</li>
</ul>
</li>
<li><p>返回值：<code>&lt;class &#39;requests.models.Response&#39;&gt;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://fanyi.baidu.com/langdetect&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;query&quot;</span>: <span class="string">&quot;垃圾&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.get(url=url, params=data, headers=headers)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;requests.models.Response&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(response.url)  <span class="comment"># https://fanyi.baidu.com/langdetect?query=%E5%9E%83%E5%9C%BE</span></span><br><span class="line">content = response.text</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="6-3-requests-put"><a href="#6-3-requests-put" class="headerlink" title="6.3 requests.put()"></a>6.3 requests.put()</h2><ul>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">put</span>(<span class="params">url: <span class="built_in">str</span> | <span class="built_in">bytes</span>,</span></span><br><span class="line"><span class="params">        data: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        *,</span></span><br><span class="line"><span class="params">        params: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        headers: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        cookies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        files: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        auth: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        timeout: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        allow_redirects: <span class="built_in">bool</span> = ...,</span></span><br><span class="line"><span class="params">        proxies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        hooks: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        stream: <span class="built_in">bool</span> | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">        verify: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        cert: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">        json: <span class="type">Any</span> | <span class="literal">None</span> = ...</span>) -&gt; Response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">put</span>(<span class="params">url, data=<span class="literal">None</span>, **kwargs</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>url</strong>：请求 url</li>
<li><strong>data</strong> ：（可选）参数为要发送到指定 url 的字典、元组列表、字节或文件对象</li>
<li><strong>kwargs</strong> ：（可选）为其他参数，比如 cookies、headers、verify</li>
</ul>
</li>
<li><p>返回值：<code>&lt;class &#39;requests.models.Response&#39;&gt;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://fanyi.baidu.com/langdetect&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;query&quot;</span>: <span class="string">&quot;垃圾&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.put(url=url, params=data, headers=headers)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;requests.models.Response&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(response.url)  <span class="comment"># https://fanyi.baidu.com/langdetect?query=%E5%9E%83%E5%9C%BE</span></span><br><span class="line">content = response.text</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="6-4-requests-delete"><a href="#6-4-requests-delete" class="headerlink" title="6.4 requests.delete()"></a>6.4 requests.delete()</h2><ul>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">delete</span>(<span class="params">url: <span class="built_in">str</span> | <span class="built_in">bytes</span>,</span></span><br><span class="line"><span class="params">           *,</span></span><br><span class="line"><span class="params">           params: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">           data: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">           headers: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">           cookies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">           files: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">           auth: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">           timeout: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">           allow_redirects: <span class="built_in">bool</span> = ...,</span></span><br><span class="line"><span class="params">           proxies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">           hooks: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">           stream: <span class="built_in">bool</span> | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">           verify: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">           cert: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">           json: <span class="type">Any</span> | <span class="literal">None</span> = ...</span>) -&gt; Response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">delete</span>(<span class="params">url, **kwargs</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>url</strong>：请求 url</li>
<li><strong>kwargs</strong> ：（可选）为其他参数，比如 cookies、headers、verify</li>
</ul>
</li>
<li><p>返回值：<code>&lt;class &#39;requests.models.Response&#39;&gt;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://httpbin.org/delete&#x27;</span></span><br><span class="line"></span><br><span class="line">response = requests.delete(url=url)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;requests.models.Response&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(response.url) </span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="6-5-requests-head"><a href="#6-5-requests-head" class="headerlink" title="6.5 requests.head()"></a>6.5 requests.head()</h2><ul>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">head</span>(<span class="params">url: <span class="built_in">str</span> | <span class="built_in">bytes</span>,</span></span><br><span class="line"><span class="params">         *,</span></span><br><span class="line"><span class="params">         params: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         data: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         headers: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         cookies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         files: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         auth: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         timeout: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         allow_redirects: <span class="built_in">bool</span> = ...,</span></span><br><span class="line"><span class="params">         proxies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         hooks: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         stream: <span class="built_in">bool</span> | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">         verify: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         cert: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">         json: <span class="type">Any</span> | <span class="literal">None</span> = ...</span>) -&gt; Response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">head</span>(<span class="params">url, **kwargs</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>url</strong>：请求 url</li>
<li><strong>kwargs</strong> ：（可选）为其他参数，比如 cookies、headers、verify</li>
</ul>
</li>
<li><p>返回值：<code>&lt;class &#39;requests.models.Response&#39;&gt;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://httpbin.org/delete&#x27;</span></span><br><span class="line">response = requests.head(url=url)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;requests.models.Response&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(response.url)  <span class="comment"># http://httpbin.org/delete</span></span><br><span class="line">content = response.text</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="6-6-requests-patch"><a href="#6-6-requests-patch" class="headerlink" title="6.6 requests.patch()"></a>6.6 requests.patch()</h2><ul>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">patch</span>(<span class="params">url: <span class="built_in">str</span> | <span class="built_in">bytes</span>,</span></span><br><span class="line"><span class="params">          data: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">          *,</span></span><br><span class="line"><span class="params">          params: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">          headers: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">          cookies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">          files: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">          auth: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">          timeout: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">          allow_redirects: <span class="built_in">bool</span> = ...,</span></span><br><span class="line"><span class="params">          proxies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">          hooks: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">          stream: <span class="built_in">bool</span> | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">          verify: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">          cert: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">          json: <span class="type">Any</span> | <span class="literal">None</span> = ...</span>) -&gt; Response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">patch</span>(<span class="params">url, data=<span class="literal">None</span>, **kwargs</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>url</strong>：请求 url</li>
<li><strong>data</strong> ：（可选）参数为要发送到指定 url 的字典、元组列表、字节或文件对象</li>
<li><strong>kwargs</strong> ：（可选）为其他参数，比如 cookies、headers、verify</li>
</ul>
</li>
<li><p>返回值：<code>&lt;class &#39;requests.models.Response&#39;&gt;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://httpbin.org/delete&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;query&quot;</span>: <span class="string">&quot;垃圾&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.patch(url=url, data=data)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;requests.models.Response&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(response.url)  <span class="comment"># http://httpbin.org/delete</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="6-7-requests-options"><a href="#6-7-requests-options" class="headerlink" title="6.7 requests.options()"></a>6.7 requests.options()</h2><ul>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">options</span>(<span class="params">url: <span class="built_in">str</span> | <span class="built_in">bytes</span>,</span></span><br><span class="line"><span class="params">            *,</span></span><br><span class="line"><span class="params">            params: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            data: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            headers: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            cookies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            files: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            auth: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            timeout: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            allow_redirects: <span class="built_in">bool</span> = ...,</span></span><br><span class="line"><span class="params">            proxies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            hooks: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            stream: <span class="built_in">bool</span> | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">            verify: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            cert: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            json: <span class="type">Any</span> | <span class="literal">None</span> = ...</span>) -&gt; Response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">options</span>(<span class="params">url, **kwargs</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>url</strong>：请求 url</li>
<li><strong>kwargs</strong> ：（可选）为其他参数，比如 cookies、headers、verify</li>
</ul>
</li>
<li><p>返回值：<code>&lt;class &#39;requests.models.Response&#39;&gt;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://httpbin.org/delete&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;query&quot;</span>: <span class="string">&quot;垃圾&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.options(url=url, params=data)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;requests.models.Response&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(response.url)  <span class="comment"># http://httpbin.org/delete?query=%E5%9E%83%E5%9C%BE</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="6-8-requests-request"><a href="#6-8-requests-request" class="headerlink" title="6.8 requests.request()"></a>6.8 requests.request()</h2><ul>
<li><p>参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">request</span>(<span class="params">method: <span class="built_in">str</span> | <span class="built_in">bytes</span>,</span></span><br><span class="line"><span class="params">            url: <span class="built_in">str</span> | <span class="built_in">bytes</span>,</span></span><br><span class="line"><span class="params">            *,</span></span><br><span class="line"><span class="params">            params: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            data: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            headers: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            cookies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            files: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            auth: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            timeout: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            allow_redirects: <span class="built_in">bool</span> = ...,</span></span><br><span class="line"><span class="params">            proxies: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            hooks: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            stream: <span class="built_in">bool</span> | <span class="literal">None</span> = ...,</span></span><br><span class="line"><span class="params">            verify: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            cert: <span class="type">Any</span> = ...,</span></span><br><span class="line"><span class="params">            json: <span class="type">Any</span> | <span class="literal">None</span> = ...</span>) -&gt; Response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">request</span>(<span class="params">method, url, **kwargs</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>method：</strong>请求方法，常见有GET、POST请求【此外还有HEAD、PUT、PATCH、DELETE、OPTIONS】（前6种就是HTTP协议所对应的请求方式，OPTIONS事实上是向服务器获取一些服务器跟客户端能够打交道的参数）</li>
<li><strong>url</strong>：请求 url</li>
<li><strong>kwargs</strong> ：（可选）为其他参数，比如 cookies、headers、verify</li>
</ul>
</li>
<li><p>返回值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://httpbin.org/delete&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;query&quot;</span>: <span class="string">&quot;垃圾&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.request(method=<span class="string">&#x27;post&#x27;</span>, url=url, data=data)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;requests.models.Response&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(response.url)  <span class="comment"># http://httpbin.org/delete</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://httpbin.org/delete&#x27;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;query&quot;</span>: <span class="string">&quot;垃圾&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.request(method=<span class="string">&#x27;post&#x27;</span>, url=url, params=data)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;requests.models.Response&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(response.url)  <span class="comment"># http://httpbin.org/delete?query=%E5%9E%83%E5%9C%BE</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="6-9-小结"><a href="#6-9-小结" class="headerlink" title="6.9 小结"></a>6.9 小结</h2><ul>
<li><p>requests.post()|requests.get()|requests.put()… …底层都是调用requests.request()方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get</span>(<span class="params">url, params=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">    <span class="keyword">return</span> request(<span class="string">&quot;get&quot;</span>, url, params=params, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">options</span>(<span class="params">url, **kwargs</span>):</span><br><span class="line">    <span class="keyword">return</span> request(<span class="string">&quot;options&quot;</span>, url, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">head</span>(<span class="params">url, **kwargs</span>):</span><br><span class="line">    kwargs.setdefault(<span class="string">&quot;allow_redirects&quot;</span>, <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> request(<span class="string">&quot;head&quot;</span>, url, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">post</span>(<span class="params">url, data=<span class="literal">None</span>, json=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">    <span class="keyword">return</span> request(<span class="string">&quot;post&quot;</span>, url, data=data, json=json, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">put</span>(<span class="params">url, data=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">    <span class="keyword">return</span> request(<span class="string">&quot;put&quot;</span>, url, data=data, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">patch</span>(<span class="params">url, data=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">    <span class="keyword">return</span> request(<span class="string">&quot;patch&quot;</span>, url, data=data, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">delete</span>(<span class="params">url, **kwargs</span>):</span><br><span class="line">    <span class="keyword">return</span> request(<span class="string">&quot;delete&quot;</span>, url, **kwargs)</span><br></pre></td></tr></table></figure>
</li>
<li><p>data、params、json区别：</p>
<ul>
<li>params在get请求中使用</li>
<li>data、json在post请求中使用</li>
<li>params是往url后面添加参数</li>
<li>data请求体</li>
<li>数据是json格式的报文，可直接使用json参数</li>
</ul>
</li>
</ul>
<h1 id="7-scrapy"><a href="#7-scrapy" class="headerlink" title="7.scrapy"></a>7.scrapy</h1><h2 id="7-1-hello-world"><a href="#7-1-hello-world" class="headerlink" title="7.1 hello world"></a>7.1 hello world</h2><ul>
<li><p>1.创建爬虫项目</p>
<ul>
<li>scrapy startproject 项目名称</li>
<li>注意：项目名称不允许数字开头 也不能包含中文</li>
</ul>
</li>
<li><p>2.创建爬虫文件</p>
<ul>
<li>要在spider文件夹中创建爬虫文件</li>
<li>scrapy genspider 爬虫文件的名字 要爬取网页</li>
<li>scrapy genspider baidu <a target="_blank" rel="noopener" href="http://www.baidu.com/">http://www.baidu.com</a></li>
</ul>
</li>
<li><p>3.运行爬虫代码</p>
<ul>
<li>scrapy crawl 爬虫文件的名字</li>
<li>scrapy crawl baidu</li>
</ul>
</li>
<li><p>爬虫文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BaiduSpider</span>(scrapy.Spider):</span><br><span class="line">    <span class="comment"># 爬虫的名字，用于运行爬虫的时候使用的值</span></span><br><span class="line">    name = <span class="string">&quot;baidu&quot;</span></span><br><span class="line">    <span class="comment"># 允许访问的域名</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;www.baidu.com&quot;</span>]</span><br><span class="line">    <span class="comment"># 起始的url地址</span></span><br><span class="line">    start_urls = [<span class="string">&quot;http://www.baidu.com&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 是执行了start_urls之后执行的方法，方法中的response就是返回的那个对象</span></span><br><span class="line">    <span class="comment"># 相当于 response = urllib.requests.urlopen()</span></span><br><span class="line">    <span class="comment">#       response = requests.get()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">type</span>(response))  <span class="comment"># &lt;class &#x27;scrapy.http.response.html.HtmlResponse&#x27;&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 起点中文网</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CarSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;car&quot;</span></span><br><span class="line">    <span class="comment"># 可以注释掉</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;www.qidian.com/rank/recom/&quot;</span>]</span><br><span class="line">    start_urls = [<span class="string">&quot;https://www.qidian.com/rank/recom/&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=====================&quot;</span>)</span><br><span class="line">        name_list = response.xpath(<span class="string">&#x27;//ul/li/div[@class=&quot;book-mid-info&quot;]/h2/a/text()&#x27;</span>)</span><br><span class="line">        author_list = response.xpath(<span class="string">&#x27;//ul/li/div[@class=&quot;book-mid-info&quot;]/p/a[@class=&quot;name&quot;]/text()&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(name_list)):</span><br><span class="line">            name = name_list[i]</span><br><span class="line">            author = author_list[i]</span><br><span class="line">            <span class="built_in">print</span>(name.extract(), author.extract())</span><br></pre></td></tr></table></figure>
</li>
<li><p>目录结构：</p>
<p><img src="image-20231026002548946.png" alt="python爬虫入门篇/image-20231026002548946"></p>
<ul>
<li>scrapy.cfg：爬虫项目的配置文件</li>
<li><code>__init__.py</code>：爬虫项目的初始化文件，用来对项目做初始化工作</li>
<li>items.py：爬虫项目的数据容器文件，用来定义要获取的数据</li>
<li>pipelines.py：爬虫项目的管道文件，用来对items中的数据进行进一步的加工处理</li>
<li>settings.py：爬虫项目的设置文件，包含了爬虫项目的设置信息</li>
<li>middlewares.py：爬虫项目的中间件文件</li>
<li>spiders：目录下创建爬虫文件</li>
</ul>
</li>
</ul>
<h2 id="7-2-settings-py配置文件"><a href="#7-2-settings-py配置文件" class="headerlink" title="7.2 settings.py配置文件"></a>7.2 settings.py配置文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Scrapy settings for scrapy_baidu project</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># For simplicity, this file contains only settings considered important or</span></span><br><span class="line"><span class="comment"># commonly used. You can find more settings consulting the documentation:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     https://docs.scrapy.org/en/latest/topics/settings.html</span></span><br><span class="line"><span class="comment">#     https://docs.scrapy.org/en/latest/topics/downloader-middleware.html</span></span><br><span class="line"><span class="comment">#     https://docs.scrapy.org/en/latest/topics/spider-middleware.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬虫项目名字</span></span><br><span class="line">BOT_NAME = <span class="string">&quot;scrapy_baidu&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在此目录下运行爬虫文件</span></span><br><span class="line">SPIDER_MODULES = [<span class="string">&quot;scrapy_baidu.spiders&quot;</span>]</span><br><span class="line"><span class="comment"># 在此目录下新建爬虫文件</span></span><br><span class="line">NEWSPIDER_MODULE = <span class="string">&quot;scrapy_baidu.spiders&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span></span><br><span class="line"><span class="comment"># 对请求头中User-AGENT进行设置</span></span><br><span class="line"><span class="comment"># USER_AGENT = &quot;scrapy_baidu (+http://www.yourdomain.com)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line"><span class="comment"># 注释之后，那么就不遵守robots协议，是一个君子协议，一般情况下，我们不遵守</span></span><br><span class="line"><span class="comment"># ROBOTSTXT_OBEY = True</span></span><br><span class="line"><span class="comment"># Configure maximum concurrent requests performed by Scrapy (default: 16)</span></span><br><span class="line"><span class="comment"># 配置Scrapy执行的最大并发请求数</span></span><br><span class="line"><span class="comment"># CONCURRENT_REQUESTS = 32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure a delay for requests for the same website (default: 0)</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay</span></span><br><span class="line"><span class="comment"># See also autothrottle settings and docs</span></span><br><span class="line"><span class="comment"># 下载器延迟3秒</span></span><br><span class="line"><span class="comment"># DOWNLOAD_DELAY = 3</span></span><br><span class="line"><span class="comment"># The download delay setting will honor only one of:</span></span><br><span class="line"><span class="comment"># 对单个网站进行并发请求的最大值</span></span><br><span class="line"><span class="comment"># CONCURRENT_REQUESTS_PER_DOMAIN = 16</span></span><br><span class="line"><span class="comment"># 对单个IP进行并发请求的最大值</span></span><br><span class="line"><span class="comment"># CONCURRENT_REQUESTS_PER_IP = 16</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable cookies (enabled by default)</span></span><br><span class="line"><span class="comment"># 是否携带cookies (默认True),设置为False可以起到禁用cookies的作用</span></span><br><span class="line"><span class="comment"># COOKIES_ENABLED = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable Telnet Console (enabled by default)</span></span><br><span class="line"><span class="comment"># 是一个扩展插件,通过TELENET可以监听到当前爬虫的一些状态,默认是True开启状态</span></span><br><span class="line"><span class="comment"># TELNETCONSOLE_ENABLED = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Override the default request headers:</span></span><br><span class="line"><span class="comment"># 设置默认请求头(会被局部headers覆盖)</span></span><br><span class="line"><span class="comment"># DEFAULT_REQUEST_HEADERS = &#123;</span></span><br><span class="line"><span class="comment">#    &quot;Accept&quot;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&quot;,</span></span><br><span class="line"><span class="comment">#    &quot;Accept-Language&quot;: &quot;en&quot;,</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable or disable spider middlewares</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/spider-middleware.html</span></span><br><span class="line"><span class="comment"># SPIDER_MIDDLEWARES = &#123;</span></span><br><span class="line"><span class="comment">#    &quot;scrapy_baidu.middlewares.ScrapyBaiduSpiderMiddleware&quot;: 543,</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable or disable downloader middlewares</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html</span></span><br><span class="line"><span class="comment"># DOWNLOADER_MIDDLEWARES = &#123;</span></span><br><span class="line"><span class="comment">#    &quot;scrapy_baidu.middlewares.ScrapyBaiduDownloaderMiddleware&quot;: 543,</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable or disable extensions</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/extensions.html</span></span><br><span class="line"><span class="comment"># EXTENSIONS = &#123;</span></span><br><span class="line"><span class="comment">#    &quot;scrapy.extensions.telnet.TelnetConsole&quot;: None,</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure item pipelines</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="comment"># 配置数据处理管道的设置。可以通过设置数字来指定管道的优先级，数字越小，优先级越高</span></span><br><span class="line"><span class="comment"># ITEM_PIPELINES = &#123;</span></span><br><span class="line"><span class="comment">#    &quot;scrapy_baidu.pipelines.ScrapyBaiduPipeline&quot;: 300,</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable and configure the AutoThrottle extension (disabled by default)</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/autothrottle.html</span></span><br><span class="line"><span class="comment"># AUTOTHROTTLE_ENABLED = True</span></span><br><span class="line"><span class="comment"># The initial download delay</span></span><br><span class="line"><span class="comment"># AUTOTHROTTLE_START_DELAY = 5</span></span><br><span class="line"><span class="comment"># The maximum download delay to be set in case of high latencies</span></span><br><span class="line"><span class="comment"># AUTOTHROTTLE_MAX_DELAY = 60</span></span><br><span class="line"><span class="comment"># The average number of requests Scrapy should be sending in parallel to</span></span><br><span class="line"><span class="comment"># each remote server</span></span><br><span class="line"><span class="comment"># AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0</span></span><br><span class="line"><span class="comment"># Enable showing throttling stats for every response received:</span></span><br><span class="line"><span class="comment"># AUTOTHROTTLE_DEBUG = False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable and configure HTTP caching (disabled by default)</span></span><br><span class="line"><span class="comment"># See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings</span></span><br><span class="line"><span class="comment"># 是否启用HTTP缓存</span></span><br><span class="line"><span class="comment"># HTTPCACHE_ENABLED = True</span></span><br><span class="line"><span class="comment"># 早于此时间的缓存请求将被重新下载。如果为零，则缓存 请求永远不会过期</span></span><br><span class="line"><span class="comment"># HTTPCACHE_EXPIRATION_SECS = 0</span></span><br><span class="line"><span class="comment"># 用于存储（低级）HTTP缓存的目录。如果为空，则HTTP 缓存将被禁用。如果给定了相对路径，则相对于项目数据目录</span></span><br><span class="line"><span class="comment"># HTTPCACHE_DIR = &quot;httpcache&quot;</span></span><br><span class="line"><span class="comment"># 不要缓存哪些HTTP代码的响应</span></span><br><span class="line"><span class="comment"># HTTPCACHE_IGNORE_HTTP_CODES = []</span></span><br><span class="line"><span class="comment"># 实现该高速缓存存储后端的类</span></span><br><span class="line"><span class="comment"># HTTPCACHE_STORAGE = &quot;scrapy.extensions.httpcache.FilesystemCacheStorage&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set settings whose default value is deprecated to a future-proof value</span></span><br><span class="line">REQUEST_FINGERPRINTER_IMPLEMENTATION = <span class="string">&quot;2.7&quot;</span></span><br><span class="line"><span class="comment"># Scrapy将在还没有安装其他反应堆的情况下安装这个反应堆</span></span><br><span class="line">TWISTED_REACTOR = <span class="string">&quot;twisted.internet.asyncioreactor.AsyncioSelectorReactor&quot;</span></span><br><span class="line"><span class="comment"># 如果未设置或设置为None（默认值），则除JSON输出外，所有内容都使用UTF-8， 由于历史原因，它使用安全的数字编码（\uXXXX序列）</span></span><br><span class="line"><span class="comment"># 如果想用UTF-8来表示JSON，请使用utf-8</span></span><br><span class="line"><span class="comment"># 在版本2.8中更改：startproject命令现在将此设置设置为 utf-8在生成的settings.py文件中</span></span><br><span class="line">FEED_EXPORT_ENCODING = <span class="string">&quot;utf-8&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="7-3-scrapy架构"><a href="#7-3-scrapy架构" class="headerlink" title="7.3 scrapy架构"></a>7.3 scrapy架构</h2><ul>
<li>Scrapy Engine(引擎)：负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等</li>
<li>Scheduler(调度器)：它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎</li>
<li>Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理</li>
<li>Spider（爬虫）：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)</li>
<li>Item Pipeline(管道)：它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方</li>
<li>Downloader Middlewares（下载中间件）：一个可以自定义扩展下载功能的组件</li>
<li>Spider Middlewares（Spider中间件）：一个可以自定扩展和操作引擎和Spider中间通信的功能组件</li>
</ul>
<h2 id="7-4-引擎"><a href="#7-4-引擎" class="headerlink" title="7.4 引擎"></a>7.4 引擎</h2><h2 id="7-5-调度器"><a href="#7-5-调度器" class="headerlink" title="7.5 调度器"></a>7.5 调度器</h2><h2 id="7-6-下载器"><a href="#7-6-下载器" class="headerlink" title="7.6 下载器"></a>7.6 下载器</h2><h2 id="7-7-爬虫"><a href="#7-7-爬虫" class="headerlink" title="7.7 爬虫"></a>7.7 爬虫</h2><h2 id="7-8-管道"><a href="#7-8-管道" class="headerlink" title="7.8 管道"></a>7.8 管道</h2><h2 id="7-9-下载器中间件"><a href="#7-9-下载器中间件" class="headerlink" title="7.9 下载器中间件"></a>7.9 下载器中间件</h2><h2 id="7-10-爬虫中间件"><a href="#7-10-爬虫中间件" class="headerlink" title="7.10 爬虫中间件"></a>7.10 爬虫中间件</h2>
    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>峡谷杨爹
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://xiaguyangdie.github.io/2023/10/23/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E7%AF%87/" title="python爬虫入门篇">https://xiaguyangdie.github.io/2023/10/23/python爬虫入门篇/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E6%B5%8B%E8%AF%95/" rel="tag"><i class="fa fa-tag"></i> 测试</a>
              <a href="/tags/%E7%88%AC%E8%99%AB/" rel="tag"><i class="fa fa-tag"></i> 爬虫</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/09/27/Flask/" rel="prev" title="Flask">
      <i class="fa fa-chevron-left"></i> Flask
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/10/29/HttpClient/" rel="next" title="HttpClient">
      HttpClient <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-urllib"><span class="nav-text">1.urllib</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-urllib-request"><span class="nav-text">1.1 urllib.request</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-1-urllib-request-urlopen"><span class="nav-text">1.1.1 urllib.request.urlopen()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-2-urllib-request-urlretrieve"><span class="nav-text">1.1.2 urllib.request.urlretrieve()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-3-urllib-request-Request"><span class="nav-text">1.1.3 urllib.request.Request()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-4-urllib-request-ProxyHandler"><span class="nav-text">1.1.4 urllib.request.ProxyHandler()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-5-urllib-request-build-opener"><span class="nav-text">1.1.5 urllib.request.build_opener()</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-urllib-parse"><span class="nav-text">1.2 urllib.parse</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-1-urllib-parse-urlparse"><span class="nav-text">1.2.1 urllib.parse.urlparse()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-2-urllib-parse-quote"><span class="nav-text">1.2.2 urllib.parse.quote()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-3-urllib-parse-urlencode"><span class="nav-text">1.2.3 urllib.parse.urlencode()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-4-urllib-parse-unquote"><span class="nav-text">1.2.4 urllib.parse.unquote()</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-urllib-error"><span class="nav-text">1.3 urllib.error</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-1-urllib-error-ContentTooShortError"><span class="nav-text">1.3.1 urllib.error.ContentTooShortError</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-2-urllib-error-HTTPError"><span class="nav-text">1.3.2 urllib.error.HTTPError</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-3-urllib-error-URLError"><span class="nav-text">1.3.3 urllib.error.URLError</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-urllib-robotparser"><span class="nav-text">1.4 urllib.robotparser</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-1-urllib-robotparser-RobotFileParser"><span class="nav-text">1.4.1 urllib.robotparser.RobotFileParser</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-2-urllib-robotparser-RuleLine"><span class="nav-text">1.4.2 urllib.robotparser.RuleLine</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-3-urllib-robotparser-Entry"><span class="nav-text">1.4.3 urllib.robotparser.Entry</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-5-urllib-response"><span class="nav-text">1.5 urllib.response</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-lxml"><span class="nav-text">2.lxml</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-jsonpath"><span class="nav-text">3. jsonpath</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-bs4"><span class="nav-text">4. bs4</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-selenium"><span class="nav-text">5.selenium</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-requests-%E9%87%8D%E7%82%B9"><span class="nav-text">6.requests(重点)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-requests-post"><span class="nav-text">6.1 requests.post()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-requests-get"><span class="nav-text">6.2  requests.get()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-3-requests-put"><span class="nav-text">6.3 requests.put()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-4-requests-delete"><span class="nav-text">6.4 requests.delete()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-5-requests-head"><span class="nav-text">6.5 requests.head()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-6-requests-patch"><span class="nav-text">6.6 requests.patch()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-7-requests-options"><span class="nav-text">6.7 requests.options()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-8-requests-request"><span class="nav-text">6.8 requests.request()</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-9-%E5%B0%8F%E7%BB%93"><span class="nav-text">6.9 小结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-scrapy"><span class="nav-text">7.scrapy</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#7-1-hello-world"><span class="nav-text">7.1 hello world</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-2-settings-py%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-text">7.2 settings.py配置文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-3-scrapy%E6%9E%B6%E6%9E%84"><span class="nav-text">7.3 scrapy架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-4-%E5%BC%95%E6%93%8E"><span class="nav-text">7.4 引擎</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-5-%E8%B0%83%E5%BA%A6%E5%99%A8"><span class="nav-text">7.5 调度器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-6-%E4%B8%8B%E8%BD%BD%E5%99%A8"><span class="nav-text">7.6 下载器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-7-%E7%88%AC%E8%99%AB"><span class="nav-text">7.7 爬虫</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-8-%E7%AE%A1%E9%81%93"><span class="nav-text">7.8 管道</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-9-%E4%B8%8B%E8%BD%BD%E5%99%A8%E4%B8%AD%E9%97%B4%E4%BB%B6"><span class="nav-text">7.9 下载器中间件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-10-%E7%88%AC%E8%99%AB%E4%B8%AD%E9%97%B4%E4%BB%B6"><span class="nav-text">7.10 爬虫中间件</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="峡谷杨爹"
      src="/images/%E5%8D%9A%E5%AE%A2.webp">
  <p class="site-author-name" itemprop="name">峡谷杨爹</p>
  <div class="site-description" itemprop="description">write less, do more</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">148</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">52</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/xiaguyangdie" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xiaguyangdie" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:424793597@qq.com" title="E-Mail → mailto:424793597@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
	</div>
	<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=450 src="//music.163.com/outchain/player?type=0&id=7450004106&auto=0&height=430"></iframe>  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">峡谷杨爹</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">2.9m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">44:15</span>
</div>

        






<script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"jc38mXtIY9GP4HNtOg9qT7Fo-gzGzoHsz","app_key":"yDHjFefMRYGX7YloQFcPnw78","server_url":null,"security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'jc38mXtIY9GP4HNtOg9qT7Fo-gzGzoHsz',
      appKey     : 'yDHjFefMRYGX7YloQFcPnw78',
      placeholder: "说说",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
